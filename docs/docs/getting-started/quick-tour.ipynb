{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7-tQfVM_pJcr"
   },
   "source": [
    "<div ithed=\"colab_button\">\n",
    "  <h1>Quick tour</h1>\n",
    "  <a target=\"_blank\" href=\"https://colab.research.google.com/github/mithril-security/blindbox/blob/main/docs/docs/getting-started/quick-tour.ipynb\"> \n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "</div>\n",
    "______________________________\n",
    "\n",
    "## Introduction\n",
    "______________________________\n",
    "\n",
    "\n",
    "**BlindBox** is a **privacy solution** allowing developers to deploy their **Software-as-a-Service** (SaaS) applications, while **keeping** their users' data **confidential**. We use **secure enclaves**, hardware based isolated environments, to **protect data during computation**. What happens in the enclave, stays in the enclave - hence our name, BlindBox!\n",
    "\n",
    "### Key Features \n",
    "\n",
    "âŒ› *COMING SOON*\n",
    "\n",
    "* Easy-to-use **CLI tool** for **deploying Docker images** in secure enclaves\n",
    "* **Data** protected by **hardware security** and customizable security options\n",
    "\n",
    "## Quick start guide\n",
    "______________________\n",
    "\n",
    "While we continue to develop BlindBox's key features, we have created this guide to demonstrate what a SaaS solution deployed with BlindBox could look like. To do this, we built a small API which serves the Whisper and OpenChatKit models within an **AWS Nitro Enclave**. We will show you how to **install and use** the **Python library** needed to query these models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eyZHW8TvpJc1"
   },
   "source": [
    "### Installation\n",
    "\n",
    "Before we can install BlindBox, we must ensure we have python3.10 installed. \n",
    "\n",
    "If you are running this in our Google Colab notebook, you will need to run the following code block since Google Colabs currently only come with python3.8 and python3.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install python3.10 & pip for python3.10\n",
    "!sudo apt install python3.10\n",
    "!curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will need to install the [blindbox](https://pypi.org/project/blindbox/) **Python library** and download a [test audio file](https://www2.cs.uic.edu/~i101/SoundFiles/taunt.wav) which we will use to test out the Whisper API. The one we'll use as an example was provided by the University of Illinois at Chicago  as part of their Computer Science 101 course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "169vRU_vpJc4",
    "outputId": "84758615-d31c-42cf-a343-d492bbec326c"
   },
   "outputs": [],
   "source": [
    "# install blindbox\n",
    "!pip install blindbox\n",
    "!pip install blindbox[ai]\n",
    "\n",
    "# Download our example audio file and save it as `taunt.wav`\n",
    "!wget https://www2.cs.uic.edu/~i101/SoundFiles/taunt.wav -O taunt.wav"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying OpenChatKit\n",
    "\n",
    "We can query the OpenChatKit model by using the `create()` method within the `blindbox.ai.Completion` module.\n",
    "\n",
    "We provide our prompt to be sent to the model as an argument to this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laura/blindbox/.venv/lib/python3.10/site-packages/blindbox/ai/connection.py:45: NitroDebugModeWarning: BlindAI is running in debug mode. This mode is provided solely for testing purposes. It MUST NOT be used in production. To deactivate debug mode pass the expected pcr0 of the enclave.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<human>: Provide me with a Python function to print Hello World\n",
      "<bot>: \n",
      "# Here is a Python function to print Hello World\n",
      "\n",
      "print(\\\"Hello World\\\")\n",
      "<human>:\"\n"
     ]
    }
   ],
   "source": [
    "import blindbox\n",
    "\n",
    "# query OpenChatKit\n",
    "code = blindbox.ai.Completion.create(\"Provide me with a Python function to print Hello World\")\n",
    "\n",
    "# print out result\n",
    "print(code.replace('\\\\n', '\\n')) #we use replace to interpret new lines correctly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method returns our query followed by the OpenChatKit bot's response.\n",
    "\n",
    "> As highlighted in the warning above, this demo API is only running Nitro attestation in debug mode. This means attestation is simulated in software and does not provide the full protection of attestation. This demo API should therefore be used for testing-purposes only and not used in production with sensitive data. We will be implementing production-ready attestation in our up-coming BlindBox release!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ERGjq-kWpJc7"
   },
   "source": [
    "### Querying the Whisper model\n",
    "\n",
    "Speech-to-text operations are handled within the `Audio.transcribe` module of `BlindBox.ai.Audio`.\n",
    "\n",
    "To transcribe an audio file, we call the `transcribe()` method. We'll provide it with **the path to our audio file** as the `file` option. \n",
    "\n",
    "The Whisper model accepts a variety of audio file formats (m4a, mp3, mp4, mpeg, mpga, wav, webm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273,
     "referenced_widgets": [
      "ee84f4d759f34951a91a5a1b455208ad",
      "2cd128aa0f3d46bc8170bfc4a7c84b42",
      "60ae2a98c06741029653cf9c30a821a5",
      "4ead236935e54af49afc0b4980069195",
      "e6653a9cc5274c75a5f7a6c92bc6f9da",
      "5157f8008edb4200b68389b05524a02c",
      "c39c98e0429f4f60869b4d5788392383",
      "1c7bf304a3b0459582b3b9b00081fdd6",
      "1fae9b7a44994a008cb8bb252e685687",
      "60495b7a331f47a4930096fe32e20c4a",
      "d4e1ea5ef241436faa57799a1ce9c16b",
      "2710f779e19946058617870bd0da4f95",
      "6d5d0205b7d9427383bc31aaed3ff1fa",
      "bbdb6ed65bb643c891a33cae67338c1e",
      "6d6d8545e65b438eb3ad04fdd3fcb523",
      "74404a89a6c14f89aca54b30728e230f",
      "033fd5b05f9e4a78a722ca26a345bb3c",
      "39b165663ddd421ca8752e8feba65865",
      "816a7897f85144e4b998b9e28cf466aa",
      "d09544c3d67d41fda6ebaa478ae9e5cc",
      "f39fd6afe02a4885896cc584f690f879",
      "6131a0a6c8a24fcb9230c3e472594140",
      "2f5c32f982bb4162a5e64e3dc6448738",
      "4493aec3b9eb45cd957558dc26787ed0",
      "1e9ebe05821c46b0b23413f51c8359b9",
      "88ec36be4d054191aaf82b550e6f073c",
      "eb74b7b0a973437085d343de925d7231",
      "d12b7be2981c43e19fa382719ff1c8d4",
      "dff9989f6cac49b595ae0cd214a01782",
      "d43ef1c2420c4404b55a3382509b5cda",
      "60902f59155040efaadf53b932db327a",
      "f3563900a4ad450c892f15abf6c6e699",
      "844e422fead140acbc0a6c9a43210c6b",
      "8fbd72b5d88a4541b4250917c4348ad1",
      "e3ee9c2925824a61ad77392c32a24bca",
      "b9e0d70632de4b0383ff482d1490f376",
      "7e5de6d7f09448c9a7ffbed90767728e",
      "946d166d8dc147c6a809776a6643a617",
      "ae40764fcfa148c6a3692f80d3cccd09",
      "44720415a71343fdb025f1dd1c2568e7",
      "78b3f6e59b944b799f640caf1ba881fb",
      "7e4f3efb85cc415d97c1ec68f30d1b22",
      "cfc656d292524fc2b1ed1886161e5efc",
      "f159743fb4eb481f97cc1f5a87da17c1",
      "131e7f70ffae445abb18f217656c19e1",
      "93412079cd064d1e87e60aee53c60e6e",
      "dd8044dc18664a759b6a9cb0f0fe0af0",
      "c14611b41d1c4d5da2c2716652c7ea81",
      "2dd6172804614fd6a36119bebbe35614",
      "6e0f131f29674861979c2a9c99bdf43e",
      "8e5cc6416c6444d386f28b1c13d297fb",
      "f9ad47b633874822886cc27363b2bcb1",
      "0bcf054117d344e29055d2094bbbd784",
      "40f3ab6379074a87b7ee823acc2e57f5",
      "2da8072665384f3fbffa53234b581178",
      "e663fcefc1824576898a9b2903be164f",
      "2153525666b84829b4797cdfb1b820b3",
      "dba0e84c053442348e272e0cbba2b3a7",
      "6e7948c385714b57bf693ac16e33fa26",
      "8c7575c221f24eb4bcb5e3f59faea6cb",
      "6daf9a3b95274b1889402321fe6cf43d",
      "8c67134ac5584ee5a921c0d7a421ddb3",
      "b63ea64575f64a838193ef1e57792fc0",
      "8703bef47e864fc08c8b7603ead3aa53",
      "462d82a18ff4497a92a2544bc09ee63d",
      "e3461dec5d1e472f982cbf331b50d83d",
      "9ac05cfc18f24be7b532c57d0e671f10",
      "2077fc95d4d846ff998cd508096eddb4",
      "54cd6b54db344d31986f5fa6eea60f63",
      "46071c3cafc949219e9fb526b7a8183a",
      "7354a1e8a5064df1908b385508b36d8b",
      "20775b71b9cf4204aad7c93b2fe51d41",
      "7cba9c4f745f486489fadb646844472a",
      "60bbcf95c0394fe185e54048dfaff257",
      "edda9299e7dc4111b3bfbfbf57faa7d0",
      "8a611e4466034ec3941b34a40dc63141",
      "cd2d631b6d36469c8fb323cbff0c9e75",
      "fcc64f5b355641d6ae666de9d3a1fdea",
      "a71daf69814a4e978d60559229b01b09",
      "378c850824b74707af12fe6a6cbe32a7",
      "48bdb108621141bf9ee7708e190227a4",
      "cd678dd8a42942d2a24365151d73fc97",
      "b650175af27947b092855da90abd9144",
      "4b46beeae1114f75a730e5b74b9bb599",
      "c207f8913def41d8af876a68168b5661",
      "55393379502f4325bca8928346b59c6b",
      "f4d78d75393446ed99af43e70cbf442a",
      "2db617c1936848dabe5dad3715afc345"
     ]
    },
    "id": "U156nalXpJc9",
    "outputId": "f9733f35-72e3-480d-e40e-30b6f52eba8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laura/.local/lib/python3.10/site-packages/blindbox/ai/connection.py:45: NitroDebugModeWarning: BlindAI is running in debug mode. This mode is provided solely for testing purposes. It MUST NOT be used in production. To deactivate debug mode pass the expected pcr0 of the enclave.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transcript = blindbox.ai.Audio.transcribe(\"taunt.wav\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ueVmCHykpJdB"
   },
   "source": [
    "This `transcribe()` method performs several steps:\n",
    "\n",
    "1. It first connects to the Mithril server, which serves the BlindBox API models in a Nitro enclave. \n",
    "2. Before communication between the client and the enclave can be established, security checks are performed through the attestation process (see the [how we protect your data page](./confidential_computing.md) for details).\n",
    "3. Once communication is established, the method uploads the user's audio data directly to the enclave and queries the specified model.\n",
    "4. The model's results are returned to the client.\n",
    "\n",
    "We can print out the returned `transcript` string variable to check our results are as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-RIltp58pJdB",
    "outputId": "5c435f8c-6863-4493-fcb3-237352bcd46c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" Now go away, or I shall taunt you a second timer!\"\n"
     ]
    }
   ],
   "source": [
    "print(transcript)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fww_D5W22wlv"
   },
   "source": [
    "Our audio file has been correctly transcribed! \n",
    "\n",
    "Feel free to test this out with your own audio files ðŸ”Š"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step: deploy your SaaS!\n",
    "____________________________________\n",
    "\n",
    "This demo is an example of the next release of our full BlindBox solution, allowing developers to deploy any compatible LLM application within a secure enclave!\n",
    "\n",
    "You can go check [our under the hood section](under-the-hood.md) to learn more about the technology behind BlindBox's Whisper API and how it works and check out the [API deployment guide](../how-to-guides/deploy-API-server.md) to see how you can deploy the API demo server."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to verify BlindBox's security features\n",
    "___________________________________________\n",
    "\n",
    "- Our source code is `open source`. You can inspect the code yourself on our [GitHub page](https://github.com/mithril-security/blindbox).\n",
    "\n",
    "- We aim to provide clear explanations of the technologies behind BlindBox. You can get started with [an introduction to confidential computing](https://blindbox.mithrilsecurity.io/en/latest/docs/getting-started/confidential_computing/) explaining key concepts behind BlindBox, or go with more specific explanations in our [secure enclaves guide](https://blindbox.mithrilsecurity.io/en/latest/docs/concepts/Trusted_Execution_Environments/).\n",
    "\n",
    "Also good to know: our historical product, **BlindAI**, has been **independently audited** by [Quarkslab SAS](https://www.quarkslab.com/fr/accueil/). The audit report is *coming soon*!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9dLZ16T528YV"
   },
   "source": [
    "## Community\n",
    "_________________\n",
    "\n",
    "Ask questions on our [**Github**](https://github.com/mithril-security/blindbox/issues) or on our [**Discord**](https://discord.com/invite/TxEHagpWd4). We love feedback!ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "blindbox-preview-7Yaoi9am-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
