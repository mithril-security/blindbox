# Why BlindBox?
________________

Despite the explosion of **Software-as-a-Service (SaaS) apps** over the last few years, **some companies** still **cannot use them** because the **data** they deal with is **too sensitive**. This is not only an issue of convenience and workflow. It also slows down research and innovation as some projects never happen because of the risk of **data leakage**. 

This is why we have created BlindBox, so developers can **deploy their SaaS solutions** in a highly-protected isolated environment, which ensures no one can access their data by running services within a hardware-based Trusted Execution Environment (TEE)‚Äù.

## Use Cases
_________________________________________

### Large Language Models (LLMs)

Companies and institutions have been dying to use **Large Language Models (LLMs)** like ChatGPT or GitHub Copilot **without restrictions**. But for actors with sensitive data like the codebase of a software under development, a classified government report, a client database full of personal data, this has not been possible, because **no LLM providers offer robust privacy guarantees**. 

For many industry players, this is a cybersecurity nightmare. Thousands of employees are using ChatGPT to help them with their tasks, feeding it company data that could then be accessed by any OpenAI employee.

Deploying a model in BlindBox can facilitate and increase the adoption of LLMs, because users wouldn't have to worry about their data being exposed to the service provider. 

## Next steps 
____________________________

To see a hands-on demo of BlindBox, check out our [Quick Tour](../getting-started/quick-tour.ipynb)!

To find out more about the Confidential technologies behind BlindBox, check out our [guide to Confidential Computing](../getting-started/confidential_computing.md).
