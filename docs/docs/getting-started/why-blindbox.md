# Why BlindBox?
________________

Despite the explosion of **Software-as-a-Service (SaaS) applications** over the last few years, **some organizations** still **cannot use them** because the **data** they deal with is **too sensitive**. This is not only an issue for business convenience and workflow. It also slows down research and innovation because the risk of **data leakage** prevents some projects from ever happening. 

This is why we have created BlindBox, so developers can **deploy their SaaS solutions** in a highly-protected isolated environment, which ensures no one can access their data by running services within a hardware-based Trusted Execution Environment (TEE).

> To find out more about the Confidential technologies behind BlindBox, check out our [guide to Confidential Computing](./confidential_computing.md).

___________________________________________

## Example: Large Language Models (LLMs)

In the current gold rush towards **Large Language Models (LLMs)** applications, companies and institutions have been dying to use the best models, like ChatGPT or GitHub Copilot, **without restrictions**. But this has not been possible for actors juggling sensitive data - like the codebase of a software under development, a classified government report, a client database full of personal data... Because **no LLMs providers offer robust privacy guarantees**. 

For many industry players, this is turning into a cybersecurity nightmare. Thousands of employees are using ChatGPT to help them with their tasks, feeding it company data that could then be accessed by any OpenAI employee. 

This is where BlindBox comes in. Deploying a model using our privacy tools can facilitate and increase the adoption of LLMs, because users wouldn't have to worry about their data being exposed to the service provider. 

> To see a hands-on demo of BlindBox LLM APIs, check out our [Quick Tour](./quick-tour.ipynb)!
