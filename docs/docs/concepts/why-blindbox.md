# Why BlindBox?
________________

Despite the explosion of **Software-as-a-Service (SaaS) apps** over the last few years, **some companies** still **cannot use them** because the **data** they deal with is **too sensitive**. This is not only an issue of convenience and workflow. It also slows down research and innovation as some projects never happen because of **leakage risks**. 

This is why we have created BlindBox, so developers can **deploy their SaaS solutions** in a protected highly isolated environment, which ensures no one can access their data by providing **strong hardware privacy guarantees**.

## Use Cases
_________________________________________

### Large Language Models (LLMs)

Companies and institutions have been dying to use **Large Language Models (LLMs)** like ChatGPT or GitHub Copilot **without restrictions**. You could theoretically feed them sensitive data like the codebase of a software under developpement, a classified government report, a client database full of personal data... But those scenarios are impossible right now, because **no LLM provider provides strong privacy guarantees**. For many industry players, this is a cybersecurity nightmare: for example, thousands of employees are using ChatGPT to help them in their tasks, feeding it company data that could then be accessed by any OpenAI employee.

Deploying a model in BlindBox could facilitate and increase its adoption, because clients wouldn't have to worry about their privacy being maintained. 

## Next steps 
____________________________

To see a hands-on demo of BlindBox via our Whisper API, check out our [Quick Tour](../getting-started/quick-tour.ipynb)!

To find out more about the Confidential technologies behind BlindBox, check out our [guide to Confidential Computing](../getting-started/confidential_computing.md).
